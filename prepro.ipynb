{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0cf104",
   "metadata": {},
   "source": [
    "# 00 Import LIbrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015ef6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from textblob import Word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072fc40",
   "metadata": {},
   "source": [
    "# 01 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url_data = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/jobstreet_data.csv\"\n",
    "df = pd.read_csv(url_data)\n",
    "\n",
    "# Load slang dictionary\n",
    "url_slang = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/slang.csv\"\n",
    "df_slang = pd.read_csv(url_slang)\n",
    "slang_dict = dict(zip(df_slang['slang'], df_slang['formal']))\n",
    "additional_slang = {}  \n",
    "slang_dict.update(additional_slang)\n",
    "\n",
    "# Load stopword \n",
    "url_stopwords = \"https://raw.githubusercontent.com/talitharhmd/jobstreet-scraper/main/stopword.csv\"\n",
    "stopword_manual = pd.read_csv(url_stopwords, header=None)\n",
    "custom_stopwords = set(stopword_manual.iloc[:, 0].str.lower())\n",
    "custom_stopwords.update([]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc9e85",
   "metadata": {},
   "source": [
    "# 03 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10965832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. lowercase\n",
    "def lowercase_columns(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(str).str.lower()\n",
    "    return df\n",
    "\n",
    "# 2. clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[\\n\\r\\t]+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"[,.!?]\", \"\", text)\n",
    "    return np.nan if text == \"\" else text\n",
    "\n",
    "# 3. translate to english\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    except:\n",
    "        return text \n",
    "\n",
    "# 4. replace slang\n",
    "def replace_slang(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    words = text.split()\n",
    "    return \" \".join([slang_dict.get(w, w) for w in words])\n",
    "\n",
    "# 5. tokenize\n",
    "def tokenizing_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# 6. remove stopword\n",
    "factory_stopword = StopWordRemoverFactory()\n",
    "stopwords_nltk = set(stopwords.words('english'))\n",
    "\n",
    "def remove_manual_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in custom_stopwords]\n",
    "\n",
    "# 7. lemmatization\n",
    "def lemmatize_flex(word):\n",
    "    lemma_v = Word(word).lemmatize(\"v\")\n",
    "    return lemma_v if lemma_v != word else Word(word).lemmatize(\"n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92065bab",
   "metadata": {},
   "source": [
    "# 04 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6810b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_clean = ['title', 'category', 'work_type', 'description']\n",
    "\n",
    "df = lowercase_columns(df, columns_to_clean)\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    df[f\"{col}\"] = df[col].apply(clean_text)\n",
    "\n",
    "df.dropna(subset=[f\"{col}\" for col in columns_to_clean], inplace=True)\n",
    "\n",
    "df_indo = df[df['country'] == 'indonesia'].copy()\n",
    "df_indo['description'] = df_indo['description'].apply(translate_text)\n",
    "df.update(df_indo)\n",
    "\n",
    "df['after_slang'] = df['description'].apply(replace_slang)\n",
    "df[\"tokenizing\"] = df[\"after_slang\"].apply(tokenizing_text)\n",
    "df[\"stopword_removed\"] = df[\"tokenizing\"].apply(remove_manual_stopwords)\n",
    "df[\"lemmatization\"] = df[\"stopword_removed\"].apply(lambda tokens: [lemmatize_flex(w) for w in tokens])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84bad3",
   "metadata": {},
   "source": [
    "## Saving Cleaned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d08599a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>lemmatization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data scientist financial conglomerates supervi...</td>\n",
       "      <td>analysis reporting banking financial services</td>\n",
       "      <td>[role, purpose, execute, suptech, data, analyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>mathematics statistics information sciences sc...</td>\n",
       "      <td>[job, description, responsibility, data, scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data annotator</td>\n",
       "      <td>database development administration informatio...</td>\n",
       "      <td>[job, description, key, responsibility, accura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  data scientist financial conglomerates supervi...   \n",
       "1                                     data scientist   \n",
       "2                                     data annotator   \n",
       "\n",
       "                                            category  \\\n",
       "0      analysis reporting banking financial services   \n",
       "1  mathematics statistics information sciences sc...   \n",
       "2  database development administration informatio...   \n",
       "\n",
       "                                       lemmatization  \n",
       "0  [role, purpose, execute, suptech, data, analyt...  \n",
       "1  [job, description, responsibility, data, scien...  \n",
       "2  [job, description, key, responsibility, accura...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"title\", \"description\", \"after_slang\", \"tokenizing\", \"stopword_removed\", \"lemmatization\"]]\n",
    "subset_df = df[[\"title\", \"category\", \"lemmatization\"]]\n",
    "subset_df.to_csv(\"cleaned_jobstreet.csv\", index=False)\n",
    "subset_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867ddd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd47ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
